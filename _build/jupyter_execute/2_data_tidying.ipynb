{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten aufbereiten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_df = pd.read_csv('./data/dbs_data.csv', delimiter=';', header=[2,3], encoding='ISO-8859-1', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Angaben sind nach einzelnen Bibliotheken aufgeschlüsselt. Nur die Ergebniszeile mit der Summe der Ergebnisse ist relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Bibliothek</th>\n",
       "      <th>DBS-ID</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Entleiher</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"9\" halign=\"left\">Ausg. Erwerbung</th>\n",
       "      <th>Unnamed: 92_level_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_1</th>\n",
       "      <th>Unnamed: 1_level_1</th>\n",
       "      <th>Unnamed: 2_level_1</th>\n",
       "      <th>Unnamed: 3_level_1</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>Unnamed: 92_level_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>Summe</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.656.290</td>\n",
       "      <td>7.569.035</td>\n",
       "      <td>7.470.671</td>\n",
       "      <td>7.374.911</td>\n",
       "      <td>7.266.128</td>\n",
       "      <td>7.184.461</td>\n",
       "      <td>...</td>\n",
       "      <td>99.774.184</td>\n",
       "      <td>103.423.305</td>\n",
       "      <td>103.645.088</td>\n",
       "      <td>104.384.607</td>\n",
       "      <td>108.453.615</td>\n",
       "      <td>109.684.251</td>\n",
       "      <td>111.128.657</td>\n",
       "      <td>114.050.410,26</td>\n",
       "      <td>111.786.730,4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NR               Name         Bibliothek  \\\n",
       "     Unnamed: 0_level_1 Unnamed: 1_level_1 Unnamed: 2_level_1   \n",
       "7393              Summe               <NA>               <NA>   \n",
       "\n",
       "                 DBS-ID  Entleiher                                   \\\n",
       "     Unnamed: 3_level_1       2010       2011       2012       2013   \n",
       "7393               <NA>  7.656.290  7.569.035  7.470.671  7.374.911   \n",
       "\n",
       "                            ... Ausg. Erwerbung                            \\\n",
       "           2014       2015  ...            2012         2013         2014   \n",
       "7393  7.266.128  7.184.461  ...      99.774.184  103.423.305  103.645.088   \n",
       "\n",
       "                                                                          \\\n",
       "             2015         2016         2017         2018            2019   \n",
       "7393  104.384.607  108.453.615  109.684.251  111.128.657  114.050.410,26   \n",
       "\n",
       "                    Unnamed: 92_level_0  \n",
       "               2020 Unnamed: 92_level_1  \n",
       "7393  111.786.730,4                <NA>  \n",
       "\n",
       "[1 rows x 93 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just relevant data\n",
    "sum_row = library_df.loc[(library_df[('NR','Unnamed: 0_level_1')] == 'Summe')]\n",
    "library_df = sum_row.astype('string')\n",
    "library_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Dataframe soll so aufgebaut sein, dass jede Zeile ein Jahr darstellt. In den Spalten finden sich die Ausprägungen wie zum Beispiel die Anzahl der Bibliotheksnutzer*innen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape dataframe\n",
    "library_df = pd.melt(library_df)\n",
    "library_df = library_df.rename(columns={\"variable_0\": \"variable\", 'variable_1': 'year', 'value': 'value'})\n",
    "library_df = library_df.drop([0, 1, 2, 3, 92])\n",
    "library_df = library_df.pivot(index='year', columns='variable', values='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datentypen müssen noch angepasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace decimal comma and thousand delimiter\n",
    "for label, content in library_df.iteritems():\n",
    "    library_df[label] = library_df[label].str.replace('.', '', regex=True)\n",
    "    library_df[label] = library_df[label].str.replace(',', '.', regex=True)\n",
    "\n",
    "# turn into floats\n",
    "for label, content in library_df.iteritems():\n",
    "    library_df[label] = library_df[label].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bevölkerung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = pd.read_csv('./data/pop_data.csv', delimiter=';', encoding='ISO-8859-1', header=[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Datensatz befinden sich einige Zeilen, die keine relevanten Informationen enthalten. Zudem müssen die Beschriftungen und Datentypen angepasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just relevant data\n",
    "pop_df = pop_df.drop([11, 12, 13, 14])\n",
    "\n",
    "# rename columns\n",
    "pop_df = pop_df.rename(columns={\"Unnamed: 0\": \"year\", \"Anzahl\": \"population\"})\n",
    "\n",
    "# change datatypes\n",
    "pop_df['population'] = pop_df['population'].astype(int)\n",
    "pop_df['date'] = pd.to_datetime(pop_df['year'], format='%d.%m.%Y')\n",
    "pop_df = pop_df.set_index(pop_df['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammenfassung mit weiteren Daten\n",
    "Im Dataframe werden die zwei Dataframes zusammengefasst. Zudem werden einige Daten, die nicht als Datensatz zur Verfügung stehen, händisch eingetragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        # general info\n",
    "        'year' : ([2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]),\n",
    "        'population' : pop_df['population'],\n",
    "\n",
    "        # reading habits\n",
    "        'digital_readers': ([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, 7650000, 8520000, 8680000, 9120000]),\n",
    "\n",
    "        'readers_weekly' : ([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, 11640000, 11930000, 11960000, 12620000]),\n",
    "        'readers_monthly' : ([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, 15070000, 14840000, 14730000, 14710000]),\n",
    "        'readers_once_month' : ([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, 6870000, 7060000, 7110000, 7030000]),\n",
    "\n",
    "        # publishing information\n",
    "        'ebook_sales': ([1900000, 4300000, 13200000, 21500000, 24800000, 27000000, 28100000, 29100000, 32800000, 32400000, 35800000]),\n",
    "        'book_sales': ([416000000, 401000000, 399000000, 398000000, 387000000, 380000000, 377000000, 367000000, np.nan, np.nan, np.nan]),\n",
    "\n",
    "        # library information\n",
    "        'lenders': library_df['Entleiher'].values.astype(int),\n",
    "        'lendings': library_df['Entleih. insges.'].values.astype(int),\n",
    "        'digital_lendings': library_df['Entl. virt.Best.'].values.astype(int),\n",
    "        'ebook_lendings': ([np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, 25652538, 30211532]),\n",
    "        'print_lendings': library_df['Entl. Print'].values,\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neue Daten aggregieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Datenexploration werden noch weitere Daten aggregiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total lendings and sales of books\n",
    "df['sales'] = df['ebook_sales'] + df['book_sales']\n",
    "df['lendings'] = df['digital_lendings'] + df['print_lendings']\n",
    "\n",
    "# regular readers\n",
    "df['readers'] = df['readers_weekly'] + df['readers_monthly'] + df['readers_once_month']\n",
    "\n",
    "# readers relative to the population over the years\n",
    "df['perc_digital_readers'] = df['digital_readers'] / df['population']\n",
    "df['perc_readers'] = df['readers'] / df['population']\n",
    "df['perc_lenders'] = df['lenders'] / df['population']\n",
    "\n",
    "# lenders relative to the reading population\n",
    "df['perc_lenders_readers'] = df['lenders']/df['readers']\n",
    "df['perc_nonlending_readers'] = 1-(df['lenders']/df['readers'])\n",
    "\n",
    "# lendings and sales per population\n",
    "df['lendings_per_person'] = df['lendings']/df['population']\n",
    "df['sales_per_person'] = df['sales']/df['population']\n",
    "\n",
    "# change in sales and lendings\n",
    "df['sales_change'] = df['sales'].diff()\n",
    "df['lendings_change'] = df['lendings'].diff()\n",
    "\n",
    "# lending or sale of ebook per digital reader\n",
    "df['lendings_per_digital_reader'] = df['ebook_lendings']/df['digital_readers']\n",
    "df['sales_per_digital_reader'] = df['ebook_sales']/df['digital_readers']\n",
    "\n",
    "# lendings per sale\n",
    "df['lendings_per_sale'] = df['lendings']/df['sales']\n",
    "df['ebook_lendings_per_sale'] = df['ebook_lendings']/df['ebook_sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GfK-Studie\n",
    "Da diese Daten nur grafisch dargestellt sind und nicht als Datensatz verfügbar sind, werden sie händisch eingetragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfk_df = pd.DataFrame(\n",
    "    data={\n",
    "        'medium':['analog', 'digital', 'analog', 'digital', 'analog', 'digital'],\n",
    "        'purchases':[27.8, 3.7, 5.9, 0.5, 1.5, 0.4],\n",
    "        'buyer_no':[29.6, 29.6, 9.2, 9.2, 2.6, 2.6],\n",
    "        'buyer':['Gesamt', 'Gesamt', 'Entleiher*innen analog', 'Entleiher*innen analog', 'Entleiher*innen digital', 'Entleiher*innen digital']\n",
    "    }\n",
    ")\n",
    "\n",
    "gfk_df['purchases_per_buyer'] = gfk_df['purchases']/gfk_df['buyer_no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Daten enthalten kategoriale Werte, die eine Ordnung haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_habits = CategoricalDtype(categories=['nicht mehr', 'seltener', 'genau so oft', 'öfter', 'noch nie'], ordered=True)\n",
    "\n",
    "buying_habits_df = pd.DataFrame(\n",
    "    data={\n",
    "        'medium':['analog', 'analog', 'analog', 'analog', 'analog', 'digital', 'digital', 'digital', 'digital', 'digital'],\n",
    "        'buying_habits': ['nicht mehr', 'seltener', 'genau so oft', 'öfter', 'noch nie', 'nicht mehr', 'seltener', 'genau so oft', 'öfter', 'noch nie'],\n",
    "        'percentage':[10, 33, 48, 4, 6, 13, 16, 22, 11, 38]\n",
    "    }\n",
    ")\n",
    "\n",
    "buying_habits_df['buying_habits'] = buying_habits_df['buying_habits'].astype(cat_habits)\n",
    "buying_habits_df['medium'] = pd.Categorical(buying_habits_df['medium'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten speichern\n",
    "Die Dataframes als csv-Dateien speichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './app/data/ebooks_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12796\\1254726040.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/ebooks_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./app/data/ebooks_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda\\envs\\jbook\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3480\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3481\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3482\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3483\u001b[0m         )\n\u001b[0;32m   3484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jbook\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jbook\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         ) as handles:\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jbook\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './app/data/ebooks_data.csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv('./data/ebooks_data.csv')\n",
    "df.to_csv('./app/data/ebooks_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfk_df.to_csv('./data/gfk_data.csv')\n",
    "gfk_df.to_csv('./app/data/gfk_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buying_habits_df.to_csv('./data/purchase_data.csv')\n",
    "buying_habits_df.to_csv('./app/data/purchase_data.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "513dc2e41d739bb2c947903f3c0bbf636d03aa53ab50e61c694a27481c81805e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}